{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from  itertools import combinations\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import statsmodels.stats\n",
    "\n",
    "import statsmodels.stats.multitest as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(l):\n",
    "    final = []\n",
    "    for i in range(len(l)):\n",
    "        final.append(random.choice(l))\n",
    "    return final\n",
    "\n",
    "def repeat_resample(sample_a, sample_b, num_iter = 1000):\n",
    "    difference_in_means = []#keep track of the difference in heights for each experiment\n",
    "    for i in range(num_iter):\n",
    "        resample_a = resample(sample_a)\n",
    "        resample_b = resample(sample_b)\n",
    "        difference = np.mean(resample_a) - np.mean(resample_b)\n",
    "        difference_in_means.append(difference)\n",
    "    return difference_in_means\n",
    "\n",
    "def comb_samples_to_pop(*args):\n",
    "    all_ = []\n",
    "    for i in args:\n",
    "        all_.extend(i)\n",
    "    return all_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052000000000000046 0.04887071763614726\n",
      "0.04400000000000004 0.05908152105447243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0009521250440731675"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anova_omnibus( *args, num_iter = 1000, verbose = False):\n",
    "    def get_var_bet(*args):\n",
    "        all_means = []\n",
    "        for  i in args:\n",
    "            all_means.append(np.mean(i))\n",
    "        return np.var(all_means)   \n",
    "    pop = comb_samples_to_pop(*args)\n",
    "    var_between_groups = get_var_bet(*args)\n",
    "    if verbose:\n",
    "        print(var_between_groups)\n",
    "    resampled_vars = []\n",
    "    for i in range(num_iter):\n",
    "        random.shuffle(pop)\n",
    "        means_of_groups = []\n",
    "        for i in args:\n",
    "            s = random.choices(pop, k = len(i))\n",
    "            means_of_groups.append(np.mean(s))\n",
    "        resampled_vars.append(np.var(means_of_groups))\n",
    "    diff = [var_between_groups - x for x in resampled_vars]\n",
    "    p_value =  1 - len([x for x in diff if x > 0])/len(diff)\n",
    "    return p_value\n",
    "\n",
    "def test_ominbus():\n",
    "    \n",
    "    s1 = [random.gauss(0,1) for x in range(100)]\n",
    "    s2 = [random.gauss(0,1) for x in range(100)]\n",
    "    s3 = [random.gauss(.3,1) for x in range(100)]\n",
    "    p_mine = anova_omnibus(s1, s2, s3, verbose = False, num_iter = 1000) \n",
    "    F, p = stats.f_oneway(s1, s2, s3 )\n",
    "    return p_mine, p\n",
    "   \n",
    "diffs =[]\n",
    "for i in range(100):\n",
    "    p_mine, p_theory = test_ominbus()\n",
    "    reject_mine = p_mine < .05\n",
    "    reject_theory = p_theory < .05\n",
    "    if reject_mine != reject_theory:\n",
    "        print(p_mine, p_theory)\n",
    "\n",
    "    diffs.append(p_mine - p_theory)\n",
    "np.mean(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020000000000000018 0.0003336160734123371\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    perm_mold = [45.5, 45.3, 45.4, 44.4, 44.6, 43.9, 44.6, 44.0]\n",
    "    die_casting = [44.2, 43.9, 44.7, 44.2, 44, 43.8, 44.6, 43.1]\n",
    "    plast_mold = [46, 45.9, 44.8, 46.2, 45.1, 45.5]\n",
    "    df = pd.DataFrame([perm_mold, die_casting, plast_mold ],  index = ['perm_mold', 'die_casting', 'plast_mold'])\n",
    "    return df\n",
    "def test_from_book():\n",
    "    data = get_data()\n",
    "    s1 = data.loc['perm_mold']\n",
    "    s2 = data.loc['die_casting']\n",
    "    s3 = data.loc['plast_mold'].dropna()\n",
    "    p_mine = anova_omnibus(s1, s2, s3)\n",
    "    F, p_theory = stats.f_oneway(s1, s2, s3 )\n",
    "    print(p_mine, p_theory)\n",
    "\n",
    "test_from_book()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 s2 sig is 5\n",
      "s1 s2 sig non correct is 6\n",
      "s1 s3 sig is 49\n"
     ]
    }
   ],
   "source": [
    "def compare_samples(the_dict, correction_method ='fdr_bh' ):\n",
    "    assert isinstance(the_dict, dict)\n",
    "    final = []\n",
    "    final_d = {}\n",
    "    for i in combinations(the_dict.keys(), 2):\n",
    "        s1 = the_dict[i[0]]\n",
    "        s2 = the_dict[i[1]]\n",
    "        p_value = stats.ttest_ind(s1, s2).pvalue\n",
    "        final.append([i, p_value])\n",
    "    p_values = [x[1] for x in final]\n",
    "    corrected = sm.multipletests(p_values, method = correction_method)\n",
    "    rejects = corrected[0]\n",
    "    p_adj = corrected[1]\n",
    "    for counter, i in enumerate(final):\n",
    "        final_d[i[0]] = {'p_value': i[1], 'reject':rejects[counter], 'adj_p': p_adj[counter]}\n",
    "    return final_d\n",
    "\n",
    "def test_compare_samples(num_iter = 100, correction_method = 'fdr_bh'):\n",
    "    s1_s2 = []\n",
    "    s1_s2_nc = []\n",
    "    s1_s3 = []\n",
    "    for  i in range(num_iter):\n",
    "        s1 = [random.gauss(0,1) for x in range(100)]\n",
    "        s2 = [random.gauss(0,1) for x in range(100)]\n",
    "        s3 = [random.gauss(.3,1) for x in range(100)]\n",
    "        #skipping omnibus\n",
    "        \n",
    "        result = compare_samples(\n",
    "            {'s1': s1, \n",
    "                's2': s2,\n",
    "                's3': s3\n",
    "            }, correction_method = correction_method)\n",
    "        s1_s2.append(result[('s1', 's2')]['reject'])\n",
    "        s1_s3.append(result[('s1', 's3')]['reject'])\n",
    "        s1_s2_nc.append(result[('s1', 's2')]['p_value'] < .05)\n",
    "    print('s1 s2 sig is {s}'.format(\n",
    "        s = len([x for x in s1_s2 if x])))\n",
    "    print('s1 s2 sig non correct is {s}'.format(\n",
    "        s = len([x for x in s1_s2_nc if x])))\n",
    "    print('s1 s3 sig is {s}'.format(\n",
    "        s = len([x for x in s1_s3 if x])))\n",
    "\n",
    "test_compare_samples(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non corrected sig is 10\n",
      "corrected with fdr sig is 0\n",
      "corrected with bonferroni sig is 0\n"
     ]
    }
   ],
   "source": [
    "def test_correction_factor():\n",
    "    p_values = []\n",
    "    for i in range(100):\n",
    "        s1 = [random.gauss(0,1) for x in range(100)]\n",
    "        s2 = [random.gauss(0,1) for x in range(100)]\n",
    "        p_values.append(stats.ttest_ind(s1, s2).pvalue)\n",
    "    print('non corrected sig is {l}'.format(\n",
    "        l = len([x for x in p_values if x < .05])))\n",
    "    corrected_fdr = sm.multipletests(p_values, method = 'fdr_bh')[0]\n",
    "    corrected_bonferroni = sm.multipletests(p_values, method = 'bonferroni')[0]\n",
    "    print('corrected with fdr sig is {l}'.format(\n",
    "        l = len([x for x in corrected_fdr if x])))\n",
    "    print('corrected with bonferroni sig is {l}'.format(\n",
    "        l = len([x for x in corrected_bonferroni if x])))\n",
    "test_correction_factor()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True,  True, False, False, False]), array([0.088, 0.006, 0.009, 0.088, 0.088, 0.088]), 0.008512444610847103, 0.008333333333333333)\n",
      "0.001 0.01 0.006\n",
      "0.003 0.02 0.009\n",
      "0.05 0.03 0.1\n",
      "0.06 0.03 0.09\n",
      "0.08 0.04 0.096\n",
      "0.088 0.05 0.088\n",
      "[True, True, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "def fdr(p_values, alpha = .05):\n",
    "    final = []\n",
    "    s = sorted(p_values)\n",
    "    for counter, i in enumerate(s):\n",
    "        a_p = round(alpha * (counter + 1)/len(p_values),2)\n",
    "        tp = round(i * len(p_values)/(counter + 1),4)\n",
    "        if i < a_p:\n",
    "            final.append(True)\n",
    "        else:\n",
    "            final.append(False)\n",
    "        print(i, a_p, tp)\n",
    "    return final\n",
    "method = 'bonferroni'\n",
    "method = 'fdr_bh'\n",
    "p_values = [.08, .001, .003, .05, .06,  .088]\n",
    "p_adj = sm.multipletests(p_values, method = method)\n",
    "print(p_adj)\n",
    "print(fdr(p_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
